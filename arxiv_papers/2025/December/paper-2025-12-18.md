# ArXiv Papers for 2025-12-18

## Artism: AI-Driven Dual-Engine System for Art Generation and Critique
- **Authors:** Shuai Liu, Yiqing Tian, Yang Chen, Mar Canet Sola
- **Primary Category:** cs.AI
- **Categories:** cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.15710v1](http://arxiv.org/abs/2512.15710v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15710v1)

- **Published:** 2025-12-17

### Summary:
This paper proposes a dual-engine AI architectural method designed to address the complex problem of exploring potential trajectories in the evolution of art. We present two interconnected components: AIDA (an artificial artist social network) and the Ismism Machine, a system for critical analysis. The core innovation lies in leveraging deep learning and multi-agent collaboration to enable multidimensional simulations of art historical developments and conceptual innovation patterns. The framework explores a shift from traditional unidirectional critique toward an intelligent, interactive mode of reflexive practice. We are currently applying this method in experimental studies on contemporary art concepts. This study introduces a general methodology based on AI-driven critical loops, offering new possibilities for computational analysis of art.

---

## Multi-View Foundation Models
- **Authors:** Leo Segre, Or Hirschorn, Shai Avidan
- **Primary Category:** cs.CV
- **Categories:** cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.15708v1](http://arxiv.org/abs/2512.15708v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15708v1)

- **Published:** 2025-12-17

### Summary:
Foundation models are vital tools in various Computer Vision applications. They take as input a single RGB image and output a deep feature representation that is useful for various applications. However, in case we have multiple views of the same 3D scene, they operate on each image independently and do not always produce consistent features for the same 3D point. We propose a way to convert a Foundation Model into a Multi-View Foundation Model. Such a model takes as input a set of images and outputs a feature map for each image such that the features of corresponding points are as consistent as possible. This approach bypasses the need to build a consistent 3D model of the features and allows direct manipulation in the image space. Specifically, we show how to augment Transformers-based foundation models (i.e., DINO, SAM, CLIP) with intermediate 3D-aware attention layers that help match features across different views. As leading examples, we show surface normal estimation and multi-view segmentation tasks. Quantitative experiments show that our method improves feature matching considerably compared to current foundation models.

---

## GateFusion: Hierarchical Gated Cross-Modal Fusion for Active Speaker Detection
- **Authors:** Yu Wang, Juhyung Ha, Frangil M. Ramirez, Yuchen Wang, David J. Crandall
- **Primary Category:** cs.CV
- **Categories:** cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.15707v1](http://arxiv.org/abs/2512.15707v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15707v1)

- **Published:** 2025-12-17

### Summary:
Active Speaker Detection (ASD) aims to identify who is currently speaking in each frame of a video. Most state-of-the-art approaches rely on late fusion to combine visual and audio features, but late fusion often fails to capture fine-grained cross-modal interactions, which can be critical for robust performance in unconstrained scenarios. In this paper, we introduce GateFusion, a novel architecture that combines strong pretrained unimodal encoders with a Hierarchical Gated Fusion Decoder (HiGate). HiGate enables progressive, multi-depth fusion by adaptively injecting contextual features from one modality into the other at multiple layers of the Transformer backbone, guided by learnable, bimodally-conditioned gates. To further strengthen multimodal learning, we propose two auxiliary objectives: Masked Alignment Loss (MAL) to align unimodal outputs with multimodal predictions, and Over-Positive Penalty (OPP) to suppress spurious video-only activations. GateFusion establishes new state-of-the-art results on several challenging ASD benchmarks, achieving 77.8% mAP (+9.4%), 86.1% mAP (+2.9%), and 96.1% mAP (+0.5%) on Ego4D-ASD, UniTalk, and WASD benchmarks, respectively, and delivering competitive performance on AVA-ActiveSpeaker. Out-of-domain experiments demonstrate the generalization of our model, while comprehensive ablations show the complementary benefits of each component.

---

## Learning Model Parameter Dynamics in a Combination Therapy for Bladder Cancer from Sparse Biological Data
- **Authors:** Kayode Olumoyin, Lamees El Naqa, Katarzyna Rejniak
- **Primary Category:** cs.LG
- **Categories:** cs.LG, q-bio.CB
- **ArXiv URL:** [http://arxiv.org/abs/2512.15706v1](http://arxiv.org/abs/2512.15706v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15706v1)

- **Published:** 2025-12-17

### Summary:
In a mathematical model of interacting biological organisms, where external interventions may alter behavior over time, traditional models that assume fixed parameters usually do not capture the evolving dynamics. In oncology, this is further exacerbated by the fact that experimental data are often sparse and sometimes are composed of a few time points of tumor volume. In this paper, we propose to learn time-varying interactions between cells, such as those of bladder cancer tumors and immune cells, and their response to a combination of anticancer treatments in a limited data scenario. We employ the physics-informed neural network (PINN) approach to predict possible subpopulation trajectories at time points where no observed data are available. We demonstrate that our approach is consistent with the biological explanation of subpopulation trajectories. Our method provides a framework for learning evolving interactions among biological organisms when external interventions are applied to their environment.

---

## Dynamic Rebatching for Efficient Early-Exit Inference with DREX
- **Authors:** Xuting Liu, Daniel Alexander, Siva Kesava Reddy Kakarla, Behnaz Arzani, Vincent Liu
- **Primary Category:** cs.DC
- **Categories:** cs.DC, cs.LG
- **ArXiv URL:** [http://arxiv.org/abs/2512.15705v1](http://arxiv.org/abs/2512.15705v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15705v1)

- **Published:** 2025-12-17

### Summary:
Early-Exit (EE) is a Large Language Model (LLM) architecture that accelerates inference by allowing easier tokens to be generated using only a subset of the model's layers. However, traditional batching frameworks are ill-suited for EE LLMs, as not all requests in a batch may be ready to exit at the same time. Existing solutions either force a uniform decision on the batch, which overlooks EE opportunities, or degrade output quality by forcing premature exits. We propose Dynamic Rebatching, a solution where we dynamically reorganize the batch at each early-exit point. Requests that meet the exit criteria are immediately processed, while those that continue are held in a buffer, re-grouped into a new batch, and forwarded to deeper layers. We introduce DREX, an early-exit inference system that implements Dynamic Rebatching with two key optimizations: 1) a copy-free rebatching buffer that avoids physical data movement, and 2) an EE and SLA-aware scheduler that analytically predicts whether a given rebatching operation will be profitable. DREX also efficiently handles the missing KV cache from skipped layers using memory-efficient state-copying. Our evaluation shows that DREX improves throughput by 2-12% compared to baseline approaches while maintaining output quality. Crucially, DREX completely eliminates involuntary exits, providing a key guarantee for preserving the output quality intended by the EE model.

---

## End-to-End Training for Autoregressive Video Diffusion via Self-Resampling
- **Authors:** Yuwei Guo, Ceyuan Yang, Hao He, Yang Zhao, Meng Wei, Zhenheng Yang, Weilin Huang, Dahua Lin
- **Primary Category:** cs.CV
- **Categories:** cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.15702v1](http://arxiv.org/abs/2512.15702v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15702v1)

- **Published:** 2025-12-17

### Summary:
Autoregressive video diffusion models hold promise for world simulation but are vulnerable to exposure bias arising from the train-test mismatch. While recent works address this via post-training, they typically rely on a bidirectional teacher model or online discriminator. To achieve an end-to-end solution, we introduce Resampling Forcing, a teacher-free framework that enables training autoregressive video models from scratch and at scale. Central to our approach is a self-resampling scheme that simulates inference-time model errors on history frames during training. Conditioned on these degraded histories, a sparse causal mask enforces temporal causality while enabling parallel training with frame-level diffusion loss. To facilitate efficient long-horizon generation, we further introduce history routing, a parameter-free mechanism that dynamically retrieves the top-k most relevant history frames for each query. Experiments demonstrate that our approach achieves performance comparable to distillation-based baselines while exhibiting superior temporal consistency on longer videos owing to native-length training.

---

## VLIC: Vision-Language Models As Perceptual Judges for Human-Aligned Image Compression
- **Authors:** Kyle Sargent, Ruiqi Gao, Philipp Henzler, Charles Herrmann, Aleksander Holynski, Li Fei-Fei, Jiajun Wu, Jason Zhang
- **Primary Category:** cs.CV
- **Categories:** cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.15701v1](http://arxiv.org/abs/2512.15701v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15701v1)

- **Published:** 2025-12-17

### Summary:
Evaluations of image compression performance which include human preferences have generally found that naive distortion functions such as MSE are insufficiently aligned to human perception. In order to align compression models to human perception, prior work has employed differentiable perceptual losses consisting of neural networks calibrated on large-scale datasets of human psycho-visual judgments. We show that, surprisingly, state-of-the-art vision-language models (VLMs) can replicate binary human two-alternative forced choice (2AFC) judgments zero-shot when asked to reason about the differences between pairs of images. Motivated to exploit the powerful zero-shot visual reasoning capabilities of VLMs, we propose Vision-Language Models for Image Compression (VLIC), a diffusion-based image compression system designed to be post-trained with binary VLM judgments. VLIC leverages existing techniques for diffusion model post-training with preferences, rather than distilling the VLM judgments into a separate perceptual loss network. We show that calibrating this system on VLM judgments produces competitive or state-of-the-art performance on human-aligned visual compression depending on the dataset, according to perceptual metrics and large-scale user studies. We additionally conduct an extensive analysis of the VLM-based reward design and training procedure and share important insights. More visuals are available at https://kylesargent.github.io/vlic

---

## FrontierCS: Evolving Challenges for Evolving Intelligence
- **Authors:** Qiuyang Mang, Wenhao Chai, Zhifei Li, Huanzhi Mao, Shang Zhou, Alexander Du, Hanchen Li, Shu Liu, Edwin Chen, Yichuan Wang, Xieting Chu, Zerui Cheng, Yuan Xu, Tian Xia, Zirui Wang, Tianneng Shi, Jianzhu Yao, Yilong Zhao, Qizheng Zhang, Charlie Ruan, Zeyu Shen, Kaiyuan Liu, Runyuan He, Dong Xing, Zerui Li, Zirong Zeng, Yige Jiang, Lufeng Cheng, Ziyi Zhao, Youran Sun, Wesley Zheng, Meiyuwang Zhang, Ruyi Ji, Xuechang Tu, Zihan Zheng, Zexing Chen, Kangyang Zhou, Zhaozi Wang, Jingbang Chen, Aleksandra Korolova, Peter Henderson, Pramod Viswanath, Vijay Ganesh, Saining Xie, Zhuang Liu, Dawn Song, Sewon Min, Ion Stoica, Joseph E. Gonzalez, Jingbo Shang, Alvin Cheung
- **Primary Category:** cs.LG
- **Categories:** cs.LG, cs.SE
- **ArXiv URL:** [http://arxiv.org/abs/2512.15699v1](http://arxiv.org/abs/2512.15699v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15699v1)

- **Published:** 2025-12-17

### Summary:
We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.

---

## Skyra: AI-Generated Video Detection via Grounded Artifact Reasoning
- **Authors:** Yifei Li, Wenzhao Zheng, Yanran Zhang, Runze Sun, Yu Zheng, Lei Chen, Jie Zhou, Jiwen Lu
- **Primary Category:** cs.CV
- **Categories:** cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.15693v1](http://arxiv.org/abs/2512.15693v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15693v1)

- **Published:** 2025-12-17

### Summary:
The misuse of AI-driven video generation technologies has raised serious social concerns, highlighting the urgent need for reliable AI-generated video detectors. However, most existing methods are limited to binary classification and lack the necessary explanations for human interpretation. In this paper, we present Skyra, a specialized multimodal large language model (MLLM) that identifies human-perceivable visual artifacts in AI-generated videos and leverages them as grounded evidence for both detection and explanation. To support this objective, we construct ViF-CoT-4K for Supervised Fine-Tuning (SFT), which represents the first large-scale AI-generated video artifact dataset with fine-grained human annotations. We then develop a two-stage training strategy that systematically enhances our model's spatio-temporal artifact perception, explanation capability, and detection accuracy. To comprehensively evaluate Skyra, we introduce ViF-Bench, a benchmark comprising 3K high-quality samples generated by over ten state-of-the-art video generators. Extensive experiments demonstrate that Skyra surpasses existing methods across multiple benchmarks, while our evaluation yields valuable insights for advancing explainable AI-generated video detection.

---

## mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs
- **Authors:** Jonas Pai, Liam Achenbach, Victoriano Montesinos, Benedek Forrai, Oier Mees, Elvis Nava
- **Primary Category:** cs.RO
- **Categories:** cs.RO, cs.AI, cs.CV, cs.LG
- **ArXiv URL:** [http://arxiv.org/abs/2512.15692v1](http://arxiv.org/abs/2512.15692v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15692v1)

- **Published:** 2025-12-17

### Summary:
Prevailing Vision-Language-Action Models (VLAs) for robotic manipulation are built upon vision-language backbones pretrained on large-scale, but disconnected static web data. As a result, despite improved semantic generalization, the policy must implicitly infer complex physical dynamics and temporal dependencies solely from robot trajectories. This reliance creates an unsustainable data burden, necessitating continuous, large-scale expert data collection to compensate for the lack of innate physical understanding. We contend that while vision-language pretraining effectively captures semantic priors, it remains blind to physical causality. A more effective paradigm leverages video to jointly capture semantics and visual dynamics during pretraining, thereby isolating the remaining task of low-level control. To this end, we introduce \model, a novel Video-Action Model (VAM) that pairs a pretrained Internet-scale video model with a flow matching-based action decoder conditioned on its latent representations. The decoder serves as an Inverse Dynamics Model (IDM), generating low-level robot actions from the latent representation of video-space action plans. Our extensive evaluation shows that our approach achieves state-of-the-art performance on simulated and real-world robotic manipulation tasks, improving sample efficiency by 10x and convergence speed by 2x compared to traditional VLA architectures.

---

## Multi-Modal Semantic Communication
- **Authors:** Matin Mortaheb, Erciyes Karakaya, Sennur Ulukus
- **Primary Category:** cs.LG
- **Categories:** cs.LG, cs.IT, eess.SP, eess.SY
- **ArXiv URL:** [http://arxiv.org/abs/2512.15691v1](http://arxiv.org/abs/2512.15691v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15691v1)

- **Published:** 2025-12-17

### Summary:
Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.

---

## BashArena: A Control Setting for Highly Privileged AI Agents
- **Authors:** Adam Kaufman, James Lucassen, Tyler Tracy, Cody Rushing, Aryan Bhatt
- **Primary Category:** cs.CR
- **Categories:** cs.CR, cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.15688v1](http://arxiv.org/abs/2512.15688v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15688v1)

- **Published:** 2025-12-17

### Summary:
Future AI agents might run autonomously with elevated privileges. If these agents are misaligned, they might abuse these privileges to cause serious damage. The field of AI control develops techniques that make it harder for misaligned AIs to cause such damage, while preserving their usefulness. We introduce BashArena, a setting for studying AI control techniques in security-critical environments. BashArena contains 637 Linux system administration and infrastructure engineering tasks in complex, realistic environments, along with four sabotage objectives (execute malware, exfiltrate secrets, escalate privileges, and disable firewall) for a red team to target. We evaluate multiple frontier LLMs on their ability to complete tasks, perform sabotage undetected, and detect sabotage attempts. Claude Sonnet 4.5 successfully executes sabotage while evading monitoring by GPT-4.1 mini 26% of the time, at 4% trajectory-wise FPR. Our findings provide a baseline for designing more effective control protocols in BashArena. We release the dataset as a ControlArena setting and share our task generation pipeline.

---

## Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning
- **Authors:** Zhenwen Liang, Sidi Lu, Wenhao Yu, Kishan Panaganti, Yujun Zhou, Haitao Mi, Dong Yu
- **Primary Category:** cs.LG
- **Categories:** cs.LG, cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.15687v1](http://arxiv.org/abs/2512.15687v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15687v1)

- **Published:** 2025-12-17

### Summary:
Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.

---

## A Multivariate Statistical Framework for Detection, Classification and Pre-localization of Anomalies in Water Distribution Networks
- **Authors:** Oleg Melnikov, Yurii Dorofieiev, Yurii Shakhnovskiy, Huy Truong, Victoria Degeler
- **Primary Category:** cs.LG
- **Categories:** cs.LG
- **ArXiv URL:** [http://arxiv.org/abs/2512.15685v1](http://arxiv.org/abs/2512.15685v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15685v1)

- **Published:** 2025-12-17

### Summary:
This paper presents a unified framework, for the detection, classification, and preliminary localization of anomalies in water distribution networks using multivariate statistical analysis. The approach, termed SICAMS (Statistical Identification and Classification of Anomalies in Mahalanobis Space), processes heterogeneous pressure and flow sensor data through a whitening transformation to eliminate spatial correlations among measurements. Based on the transformed data, the Hotelling's $T^2$ statistic is constructed, enabling the formulation of anomaly detection as a statistical hypothesis test of network conformity to normal operating conditions. It is shown that Hotelling's $T^2$ statistic can serve as an integral indicator of the overall "health" of the system, exhibiting correlation with total leakage volume, and thereby enabling approximate estimation of water losses via a regression model. A heuristic algorithm is developed to analyze the $T^2$ time series and classify detected anomalies into abrupt leaks, incipient leaks, and sensor malfunctions. Furthermore, a coarse leak localization method is proposed, which ranks sensors according to their statistical contribution and employs Laplacian interpolation to approximate the affected region within the network. Application of the proposed framework to the BattLeDIM L-Town benchmark dataset demonstrates high sensitivity and reliability in leak detection, maintaining robust performance even under multiple leaks. These capabilities make the method applicable to real-world operational environments without the need for a calibrated hydraulic model.

---

## High-Dimensional Partial Least Squares: Spectral Analysis and Fundamental Limitations
- **Authors:** Victor Léger, Florent Chatelain
- **Primary Category:** stat.ML
- **Categories:** stat.ML, cs.LG
- **ArXiv URL:** [http://arxiv.org/abs/2512.15684v1](http://arxiv.org/abs/2512.15684v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15684v1)

- **Published:** 2025-12-17

### Summary:
Partial Least Squares (PLS) is a widely used method for data integration, designed to extract latent components shared across paired high-dimensional datasets. Despite decades of practical success, a precise theoretical understanding of its behavior in high-dimensional regimes remains limited. In this paper, we study a data integration model in which two high-dimensional data matrices share a low-rank common latent structure while also containing individual-specific components. We analyze the singular vectors of the associated cross-covariance matrix using tools from random matrix theory and derive asymptotic characterizations of the alignment between estimated and true latent directions. These results provide a quantitative explanation of the reconstruction performance of the PLS variant based on Singular Value Decomposition (PLS-SVD) and identify regimes where the method exhibits counter-intuitive or limiting behavior. Building on this analysis, we compare PLS-SVD with principal component analysis applied separately to each dataset and show its asymptotic superiority in detecting the common latent subspace. Overall, our results offer a comprehensive theoretical understanding of high-dimensional PLS-SVD, clarifying both its advantages and fundamental limitations.

---

## Stylized Synthetic Augmentation further improves Corruption Robustness
- **Authors:** Georg Siedel, Rojan Regmi, Abhirami Anand, Weijia Shao, Silvia Vock, Andrey Morozov
- **Primary Category:** cs.CV
- **Categories:** cs.CV, cs.LG
- **ArXiv URL:** [http://arxiv.org/abs/2512.15675v1](http://arxiv.org/abs/2512.15675v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15675v1)

- **Published:** 2025-12-17

### Summary:
This paper proposes a training data augmentation pipeline that combines synthetic image data with neural style transfer in order to address the vulnerability of deep vision models to common corruptions. We show that although applying style transfer on synthetic images degrades their quality with respect to the common FID metric, these images are surprisingly beneficial for model training. We conduct a systematic empirical analysis of the effects of both augmentations and their key hyperparameters on the performance of image classifiers. Our results demonstrate that stylization and synthetic data complement each other well and can be combined with popular rule-based data augmentation techniques such as TrivialAugment, while not working with others. Our method achieves state-of-the-art corruption robustness on several small-scale image classification benchmarks, reaching 93.54%, 74.9% and 50.86% robust accuracy on CIFAR-10-C, CIFAR-100-C and TinyImageNet-C, respectively

---

## Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers
- **Authors:** Adam Karvonen, James Chua, Clément Dumas, Kit Fraser-Taliente, Subhash Kantamneni, Julian Minder, Euan Ong, Arnab Sen Sharma, Daniel Wen, Owain Evans, Samuel Marks
- **Primary Category:** cs.CL
- **Categories:** cs.CL, cs.AI, cs.LG
- **ArXiv URL:** [http://arxiv.org/abs/2512.15674v1](http://arxiv.org/abs/2512.15674v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15674v1)

- **Published:** 2025-12-17

### Summary:
Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.

---

## Explaining the Reasoning of Large Language Models Using Attribution Graphs
- **Authors:** Chase Walker, Rickard Ewetz
- **Primary Category:** cs.AI
- **Categories:** cs.AI, cs.CL
- **ArXiv URL:** [http://arxiv.org/abs/2512.15663v1](http://arxiv.org/abs/2512.15663v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15663v1)

- **Published:** 2025-12-17

### Summary:
Large language models (LLMs) exhibit remarkable capabilities, yet their reasoning remains opaque, raising safety and trust concerns. Attribution methods, which assign credit to input features, have proven effective for explaining the decision making of computer vision models. From these, context attributions have emerged as a promising approach for explaining the behavior of autoregressive LLMs. However, current context attributions produce incomplete explanations by directly relating generated tokens to the prompt, discarding inter-generational influence in the process. To overcome these shortcomings, we introduce the Context Attribution via Graph Explanations (CAGE) framework. CAGE introduces an attribution graph: a directed graph that quantifies how each generation is influenced by both the prompt and all prior generations. The graph is constructed to preserve two properties-causality and row stochasticity. The attribution graph allows context attributions to be computed by marginalizing intermediate contributions along paths in the graph. Across multiple models, datasets, metrics, and methods, CAGE improves context attribution faithfulness, achieving average gains of up to 40%.

---

## Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning
- **Authors:** Jiaqi Xu, Cuiling Lan, Xuejin Chen, Yan LU
- **Primary Category:** cs.AI
- **Categories:** cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.15662v1](http://arxiv.org/abs/2512.15662v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15662v1)

- **Published:** 2025-12-17

### Summary:
Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.

---

## Prospects for quantum advantage in machine learning from the representability of functions
- **Authors:** Sergi Masot-Llima, Elies Gil-Fuster, Carlos Bravo-Prieto, Jens Eisert, and Tommaso Guaita
- **Primary Category:** quant-ph
- **Categories:** quant-ph, cs.LG, stat.ML
- **ArXiv URL:** [http://arxiv.org/abs/2512.15661v1](http://arxiv.org/abs/2512.15661v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.15661v1)

- **Published:** 2025-12-17

### Summary:
Demonstrating quantum advantage in machine learning tasks requires navigating a complex landscape of proposed models and algorithms. To bring clarity to this search, we introduce a framework that connects the structure of parametrized quantum circuits to the mathematical nature of the functions they can actually learn. Within this framework, we show how fundamental properties, like circuit depth and non-Clifford gate count, directly determine whether a model's output leads to efficient classical simulation or surrogation. We argue that this analysis uncovers common pathways to dequantization that underlie many existing simulation methods. More importantly, it reveals critical distinctions between models that are fully simulatable, those whose function space is classically tractable, and those that remain robustly quantum. This perspective provides a conceptual map of this landscape, clarifying how different models relate to classical simulability and pointing to where opportunities for quantum advantage may lie.

---

