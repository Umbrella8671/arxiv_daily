# ArXiv Papers for 2025-12-08

## Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms
- **Authors:** Francesco Granata, Francesco Poggi, Misael Mongiovì
- **Primary Category:** cs.IR
- **Categories:** cs.IR, cs.AI, cs.CL, cs.LG
- **ArXiv URL:** [http://arxiv.org/abs/2512.05967v1](http://arxiv.org/abs/2512.05967v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05967v1)

- **Published:** 2025-12-05

### Summary:
In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answering systems in Italian. The system includes a Wikidata-based Entity Linking module and implements three re-ranking strategies to combine semantic and entity-based information: a hybrid score weighting model, reciprocal rank fusion, and a cross-encoder re-ranker. Experiments were conducted on two benchmarks: a custom academic dataset and the standard SQuAD-it dataset. Results show that, in domain-specific contexts, the hybrid schema based on reciprocal rank fusion significantly outperforms both the baseline and the cross-encoder approach, while the cross-encoder achieves the best results on the general-domain dataset. These findings confirm the presence of an effect of domain mismatch and highlight the importance of domain adaptation and hybrid ranking strategies to enhance factual precision and reliability in retrieval-augmented generation. They also demonstrate the potential of entity-aware RAG systems in educational environments, fostering adaptive and reliable AI-based tutoring tools.

---

## EditThinker: Unlocking Iterative Reasoning for Any Image Editor
- **Authors:** Hongyu Li, Manyuan Zhang, Dian Zheng, Ziyu Guo, Yimeng Jia, Kaituo Feng, Hao Yu, Yexin Liu, Yan Feng, Peng Pei, Xunliang Cai, Linjiang Huang, Hongsheng Li, Si Liu
- **Primary Category:** cs.CV
- **Categories:** cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.05965v1](http://arxiv.org/abs/2512.05965v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05965v1)

- **Published:** 2025-12-05

### Summary:
Instruction-based image editing has emerged as a prominent research area, which, benefiting from image generation foundation models, have achieved high aesthetic quality, making instruction-following capability the primary challenge. Existing approaches improve instruction adherence via supervised or reinforcement learning, yet single-turn success rates remain limited due to inherent stochasticity and a lack of deliberation. In this work, we propose a deliberative editing framework to 'think' while they edit, which simulates the human cognitive loop by iteratively executing a Think-while-Edit cycle: Critiquing results and Refining instructions , followed by Repeating the generation until satisfactory. Specifically, we train a single MLLM, EditThinker, to act as the reasoning engine of this framework, which jointly produce the critique score, reasoning process, and refined instructions. We employ reinforcement learning to align the EditThinker's thinking with its editing, thereby generating more targeted instruction improvements. Extensive experiments on four benchmarks demonstrate that our approach significantly improves the instruction-following capability of any image editing model by a large margin. We will release our data construction framework, datasets, and models to benefit the community.

---

## Training-Time Action Conditioning for Efficient Real-Time Chunking
- **Authors:** Kevin Black, Allen Z. Ren, Michael Equi, Sergey Levine
- **Primary Category:** cs.RO
- **Categories:** cs.RO, cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.05964v1](http://arxiv.org/abs/2512.05964v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05964v1)

- **Published:** 2025-12-05

### Summary:
Real-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $π_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.

---

## Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity
- **Authors:** Germán Kruszewski, Pierre Erbacher, Jos Rozen, Marc Dymetman
- **Primary Category:** cs.LG
- **Categories:** cs.LG, cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.05962v1](http://arxiv.org/abs/2512.05962v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05962v1)

- **Published:** 2025-12-05

### Summary:
Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the "mode-seeking" or "zero-forcing" Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $α$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.

---

## AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement
- **Authors:** Munsif Ali, Najmul Hassan, Lucia Ventura, Davide Di Bari, Simonepietro Canese
- **Primary Category:** cs.CV
- **Categories:** cs.CV, cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.05960v1](http://arxiv.org/abs/2512.05960v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05960v1)

- **Published:** 2025-12-05

### Summary:
Underwater images often suffer from severe color distortion, low contrast, and a hazy appearance due to wavelength-dependent light absorption and scattering. Simultaneously, existing deep learning models exhibit high computational complexity, which limits their practical deployment for real-time underwater applications. To address these challenges, this paper presents a novel underwater image enhancement model, called Adaptive Frequency Fusion and Illumination Aware Network (AQUA-Net). It integrates a residual encoder decoder with dual auxiliary branches, which operate in the frequency and illumination domains. The frequency fusion encoder enriches spatial representations with frequency cues from the Fourier domain and preserves fine textures and structural details. Inspired by Retinex, the illumination-aware decoder performs adaptive exposure correction through a learned illumination map that separates reflectance from lighting effects. This joint spatial, frequency, and illumination design enables the model to restore color balance, visual contrast, and perceptual realism under diverse underwater conditions. Additionally, we present a high-resolution, real-world underwater video-derived dataset from the Mediterranean Sea, which captures challenging deep-sea conditions with realistic visual degradations to enable robust evaluation and development of deep learning models. Extensive experiments on multiple benchmark datasets show that AQUA-Net performs on par with SOTA in both qualitative and quantitative evaluations while using less number of parameters. Ablation studies further confirm that the frequency and illumination branches provide complementary contributions that improve visibility and color representation. Overall, the proposed model shows strong generalization capability and robustness, and it provides an effective solution for real-world underwater imaging applications.

---

## M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG
- **Authors:** David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata
- **Primary Category:** cs.CL
- **Categories:** cs.CL, cs.AI, cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.05959v1](http://arxiv.org/abs/2512.05959v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05959v1)

- **Published:** 2025-12-05

### Summary:
Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.

---

## MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution
- **Authors:** Sara Patel, Mingxun Zhou, Giulia Fanti
- **Primary Category:** cs.LG
- **Categories:** cs.LG, cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.05958v1](http://arxiv.org/abs/2512.05958v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05958v1)

- **Published:** 2025-12-05

### Summary:
Generative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens--for instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.

---

## Consequences of Kernel Regularity for Bandit Optimization
- **Authors:** Madison Lee, Tara Javidi
- **Primary Category:** stat.ML
- **Categories:** stat.ML, cs.LG
- **ArXiv URL:** [http://arxiv.org/abs/2512.05957v1](http://arxiv.org/abs/2512.05957v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05957v1)

- **Published:** 2025-12-05

### Summary:
In this work we investigate the relationship between kernel regularity and algorithmic performance in the bandit optimization of RKHS functions. While reproducing kernel Hilbert space (RKHS) methods traditionally rely on global kernel regressors, it is also common to use a smoothness-based approach that exploits local approximations. We show that these perspectives are deeply connected through the spectral properties of isotropic kernels. In particular, we characterize the Fourier spectra of the Matérn, square-exponential, rational-quadratic, $γ$-exponential, piecewise-polynomial, and Dirichlet kernels, and show that the decay rate determines asymptotic regret from both viewpoints. For kernelized bandit algorithms, spectral decay yields upper bounds on the maximum information gain, governing worst-case regret, while for smoothness-based methods, the same decay rates establish Hölder space embeddings and Besov space norm-equivalences, enabling local continuity analysis. These connections show that kernel-based and locally adaptive algorithms can be analyzed within a unified framework. This allows us to derive explicit regret bounds for each kernel family, obtaining novel results in several cases and providing improved analysis for others. Furthermore, we analyze LP-GP-UCB, an algorithm that combines both approaches, augmenting global Gaussian process surrogates with local polynomial estimators. While the hybrid approach does not uniformly dominate specialized methods, it achieves order-optimality across multiple kernel families.

---

## SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models
- **Authors:** Haowen Liu, Shaoxiong Yao, Haonan Chen, Jiawei Gao, Jiayuan Mao, Jia-Bin Huang, Yilun Du
- **Primary Category:** cs.RO
- **Categories:** cs.RO, cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.05955v1](http://arxiv.org/abs/2512.05955v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05955v1)

- **Published:** 2025-12-05

### Summary:
Vision-Language Models (VLMs) exhibit remarkable common-sense and semantic reasoning capabilities. However, they lack a grounded understanding of physical dynamics. This limitation arises from training VLMs on static internet-scale visual-language data that contain no causal interactions or action-conditioned changes. Consequently, it remains challenging to leverage VLMs for fine-grained robotic manipulation tasks that require physical understanding, reasoning, and corresponding action planning. To overcome this, we present SIMPACT, a test-time, SIMulation-enabled ACTion Planning framework that equips VLMs with physical reasoning through simulation-in-the-loop world modeling, without requiring any additional training. From a single RGB-D observation, SIMPACT efficiently constructs physics simulations, enabling the VLM to propose informed actions, observe simulated rollouts, and iteratively refine its reasoning. By integrating language reasoning with physics prediction, our simulation-enabled VLM can understand contact dynamics and action outcomes in a physically grounded way. Our method demonstrates state-of-the-art performance on five challenging, real-world rigid-body and deformable manipulation tasks that require fine-grained physical reasoning, outperforming existing general-purpose robotic manipulation models. Our results demonstrate that embedding physics understanding via efficient simulation into VLM reasoning at test time offers a promising path towards generalizable embodied intelligence. Project webpage can be found at https://simpact-bot.github.io

---

## SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code
- **Authors:** Shima Imani, Seungwhan Moon, Adel Ahmadyan, Lu Zhang, Kirmani Ahmed, Babak Damavandi
- **Primary Category:** cs.AI
- **Categories:** cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.05954v1](http://arxiv.org/abs/2512.05954v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05954v1)

- **Published:** 2025-12-05

### Summary:
We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems

---

## Trusted AI Agents in the Cloud
- **Authors:** Teofil Bodea, Masanori Misono, Julian Pritzi, Patrick Sabanic, Thore Sommer, Harshavardhan Unnibhavi, David Schall, Nuno Santos, Dimitrios Stavrakakis, Pramod Bhatotia
- **Primary Category:** cs.CR
- **Categories:** cs.CR, cs.AI, cs.MA
- **ArXiv URL:** [http://arxiv.org/abs/2512.05951v1](http://arxiv.org/abs/2512.05951v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05951v1)

- **Published:** 2025-12-05

### Summary:
AI agents powered by large language models are increasingly deployed as cloud services that autonomously access sensitive data, invoke external tools, and interact with other agents. However, these agents run within a complex multi-party ecosystem, where untrusted components can lead to data leakage, tampering, or unintended behavior. Existing Confidential Virtual Machines (CVMs) provide only per binary protection and offer no guarantees for cross-principal trust, accelerator-level isolation, or supervised agent behavior. We present Omega, a system that enables trusted AI agents by enforcing end-to-end isolation, establishing verifiable trust across all contributing principals, and supervising every external interaction with accountable provenance. Omega builds on Confidential VMs and Confidential GPUs to create a Trusted Agent Platform that hosts many agents within a single CVM using nested isolation. It also provides efficient multi-agent orchestration with cross-principal trust establishment via differential attestation, and a policy specification and enforcement framework that governs data access, tool usage, and inter-agent communication for data protection and regulatory compliance. Implemented on AMD SEV-SNP and NVIDIA H100, Omega fully secures agent state across CVM-GPU, and achieves high performance while enabling high-density, policy-compliant multi-agent deployments at cloud scale.

---

## Impugan: Learning Conditional Generative Models for Robust Data Imputation
- **Authors:** Zalish Mahmud, Anantaa Kotal, Aritran Piplai
- **Primary Category:** cs.LG
- **Categories:** cs.LG, cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.05950v1](http://arxiv.org/abs/2512.05950v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05950v1)

- **Published:** 2025-12-05

### Summary:
Incomplete data are common in real-world applications. Sensors fail, records are inconsistent, and datasets collected from different sources often differ in scale, sampling rate, and quality. These differences create missing values that make it difficult to combine data and build reliable models. Standard imputation methods such as regression models, expectation-maximization, and multiple imputation rely on strong assumptions about linearity and independence. These assumptions rarely hold for complex or heterogeneous data, which can lead to biased or over-smoothed estimates. We propose Impugan, a conditional Generative Adversarial Network (cGAN) for imputing missing values and integrating heterogeneous datasets. The model is trained on complete samples to learn how missing variables depend on observed ones. During inference, the generator reconstructs missing entries from available features, and the discriminator enforces realism by distinguishing true from imputed data. This adversarial process allows Impugan to capture nonlinear and multimodal relationships that conventional methods cannot represent. In experiments on benchmark datasets and a multi-source integration task, Impugan achieves up to 82\% lower Earth Mover's Distance (EMD) and 70\% lower mutual-information deviation (MI) compared to leading baselines. These results show that adversarially trained generative models provide a scalable and principled approach for imputing and merging incomplete, heterogeneous data. Our model is available at: github.com/zalishmahmud/impuganBigData2025

---

## Developing synthetic microdata through machine learning for firm-level business surveys
- **Authors:** Jorge Cisneros Paz, Timothy Wojan, Matthew Williams, Jennifer Ozawa, Robert Chew, Kimberly Janda, Timothy Navarro, Michael Floyd, Christine Task, Damon Streat
- **Primary Category:** cs.LG
- **Categories:** cs.LG, econ.GN, stat.AP, stat.ME
- **ArXiv URL:** [http://arxiv.org/abs/2512.05948v1](http://arxiv.org/abs/2512.05948v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05948v1)

- **Published:** 2025-12-05

### Summary:
Public-use microdata samples (PUMS) from the United States (US) Census Bureau on individuals have been available for decades. However, large increases in computing power and the greater availability of Big Data have dramatically increased the probability of re-identifying anonymized data, potentially violating the pledge of confidentiality given to survey respondents. Data science tools can be used to produce synthetic data that preserve critical moments of the empirical data but do not contain the records of any existing individual respondent or business. Developing public-use firm data from surveys presents unique challenges different from demographic data, because there is a lack of anonymity and certain industries can be easily identified in each geographic area. This paper briefly describes a machine learning model used to construct a synthetic PUMS based on the Annual Business Survey (ABS) and discusses various quality metrics. Although the ABS PUMS is currently being refined and results are confidential, we present two synthetic PUMS developed for the 2007 Survey of Business Owners, similar to the ABS business data. Econometric replication of a high impact analysis published in Small Business Economics demonstrates the verisimilitude of the synthetic data to the true data and motivates discussion of possible ABS use cases.

---

## Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem
- **Authors:** Truong Thanh Hung Nguyen, Truong Thinh Nguyen, Hung Cao
- **Primary Category:** cs.AI
- **Categories:** cs.AI, cs.ET, cs.SE
- **ArXiv URL:** [http://arxiv.org/abs/2512.05946v1](http://arxiv.org/abs/2512.05946v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05946v1)

- **Published:** 2025-12-05

### Summary:
Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.

---

## TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models
- **Authors:** Shima Imani, Seungwhan Moon, Lambert Mathias, Lu Zhang, Babak Damavandi
- **Primary Category:** cs.AI
- **Categories:** cs.AI
- **ArXiv URL:** [http://arxiv.org/abs/2512.05943v1](http://arxiv.org/abs/2512.05943v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05943v1)

- **Published:** 2025-12-05

### Summary:
Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.

---

## Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding
- **Authors:** Zhiyuan Jiang, Shenghao Xie, Wenyi Li, Wenqiang Zu, Peihang Li, Jiahao Qiu, Siqi Pei, Lei Ma, Tiejun Huang, Mengdi Wang, Shilong Liu
- **Primary Category:** cs.CV
- **Categories:** cs.CV, cs.AI, cs.CL
- **ArXiv URL:** [http://arxiv.org/abs/2512.05941v1](http://arxiv.org/abs/2512.05941v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05941v1)

- **Published:** 2025-12-05

### Summary:
Grounding is a fundamental capability for building graphical user interface (GUI) agents. Although existing approaches rely on large-scale bounding box supervision, they still face various challenges, such as cross-platform generalization, complex layout analysis, and fine-grained element localization. In this paper, we investigate zoom as a strong yet underexplored prior for GUI grounding, and propose a training-free method, ZoomClick. By characterizing four key properties of zoom (i.e., pre-zoom, depth, shrink size, minimal crop size), we unlock its full capabilities for dynamic spatial focusing and adaptive context switching. Experiments demonstrate that our method significantly boosts the performance of both general vision-language and specialized GUI grounding models, achieving state-of-the-art results on several mainstream benchmarks; for example, UI-Venus-72B attains a 73.1% success rate on ScreenSpot-Pro. Furthermore, we present GUIZoom-Bench, a benchmark for evaluating model adaptability to zoom, aiming to inspire future research on improving zoom for further training and test-time scaling in GUI grounding tasks.

---

## Designing an Optimal Sensor Network via Minimizing Information Loss
- **Authors:** Daniel Waxman, Fernando Llorente, Katia Lamer, Petar M. Djurić
- **Primary Category:** stat.ME
- **Categories:** stat.ME, cs.LG, stat.CO, stat.ML
- **ArXiv URL:** [http://arxiv.org/abs/2512.05940v1](http://arxiv.org/abs/2512.05940v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05940v1)

- **Published:** 2025-12-05

### Summary:
Optimal experimental design is a classic topic in statistics, with many well-studied problems, applications, and solutions. The design problem we study is the placement of sensors to monitor spatiotemporal processes, explicitly accounting for the temporal dimension in our modeling and optimization. We observe that recent advancements in computational sciences often yield large datasets based on physics-based simulations, which are rarely leveraged in experimental design. We introduce a novel model-based sensor placement criterion, along with a highly-efficient optimization algorithm, which integrates physics-based simulations and Bayesian experimental design principles to identify sensor networks that "minimize information loss" from simulated data. Our technique relies on sparse variational inference and (separable) Gauss-Markov priors, and thus may adapt many techniques from Bayesian experimental design. We validate our method through a case study monitoring air temperature in Phoenix, Arizona, using state-of-the-art physics-based simulations. Our results show our framework to be superior to random or quasi-random sampling, particularly with a limited number of sensors. We conclude by discussing practical considerations and implications of our framework, including more complex modeling tools and real-world deployments.

---

## Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception
- **Authors:** Anne Sielemann, Valentin Barner, Stefan Wolf, Masoud Roschani, Jens Ziehn, Juergen Beyerer
- **Primary Category:** cs.CV
- **Categories:** cs.CV, cs.AI, cs.RO
- **ArXiv URL:** [http://arxiv.org/abs/2512.05937v1](http://arxiv.org/abs/2512.05937v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05937v1)

- **Published:** 2025-12-05

### Summary:
Common approaches to explainable AI (XAI) for deep learning focus on analyzing the importance of input features on the classification task in a given model: saliency methods like SHAP and GradCAM are used to measure the impact of spatial regions of the input image on the classification result. Combined with ground truth information about the location of the object in the input image (e.g., a binary mask), it is determined whether object pixels had a high impact on the classification result, or whether the classification focused on background pixels. The former is considered to be a sign of a healthy classifier, whereas the latter is assumed to suggest overfitting on spurious correlations. A major challenge, however, is that these intuitive interpretations are difficult to test quantitatively, and hence the output of such explanations lacks an explanation itself. One particular reason is that correlations in real-world data are difficult to avoid, and whether they are spurious or legitimate is debatable. Synthetic data in turn can facilitate to actively enable or disable correlations where desired but often lack a sufficient quantification of realism and stochastic properties. [...] Therefore, we systematically generate six synthetic datasets for the task of traffic sign recognition, which differ only in their degree of camera variation and background correlation [...] to quantify the isolated influence of background correlation, different levels of camera variation, and considered traffic sign shapes on the classification performance, as well as background feature importance. [...] Results include a quantification of when and how much background features gain importance to support the classification task based on changes in the training domain [...].
  Download: synset.de/datasets/synset-signset-ger/background-effect

---

## Synset Signset Germany: a Synthetic Dataset for German Traffic Sign Recognition
- **Authors:** Anne Sielemann, Lena Loercher, Max-Lion Schumacher, Stefan Wolf, Masoud Roschani, Jens Ziehn
- **Primary Category:** cs.CV
- **Categories:** cs.CV, cs.RO
- **ArXiv URL:** [http://arxiv.org/abs/2512.05936v1](http://arxiv.org/abs/2512.05936v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05936v1)

- **Published:** 2025-12-05

### Summary:
In this paper, we present a synthesis pipeline and dataset for training / testing data in the task of traffic sign recognition that combines the advantages of data-driven and analytical modeling: GAN-based texture generation enables data-driven dirt and wear artifacts, rendering unique and realistic traffic sign surfaces, while the analytical scene modulation achieves physically correct lighting and allows detailed parameterization. In particular, the latter opens up applications in the context of explainable AI (XAI) and robustness tests due to the possibility of evaluating the sensitivity to parameter changes, which we demonstrate with experiments. Our resulting synthetic traffic sign recognition dataset Synset Signset Germany contains a total of 105500 images of 211 different German traffic sign classes, including newly published (2020) and thus comparatively rare traffic signs. In addition to a mask and a segmentation image, we also provide extensive metadata including the stochastically selected environment and imaging effect parameters for each image. We evaluate the degree of realism of Synset Signset Germany on the real-world German Traffic Sign Recognition Benchmark (GTSRB) and in comparison to CATERED, a state-of-the-art synthetic traffic sign recognition dataset.

---

## Physically-Based Simulation of Automotive LiDAR
- **Authors:** L. Dudzik, M. Roschani, A. Sielemann, K. Trampert, J. Ziehn, J. Beyerer, C. Neumann
- **Primary Category:** cs.RO
- **Categories:** cs.RO, cs.CV
- **ArXiv URL:** [http://arxiv.org/abs/2512.05932v1](http://arxiv.org/abs/2512.05932v1)
- **PDF URL:** [Link](https://arxiv.org/pdf/2512.05932v1)

- **Published:** 2025-12-05

### Summary:
We present an analytic model for simulating automotive time-of-flight (ToF) LiDAR that includes blooming, echo pulse width, and ambient light, along with steps to determine model parameters systematically through optical laboratory measurements. The model uses physically based rendering (PBR) in the near-infrared domain. It assumes single-bounce reflections and retroreflections over rasterized rendered images from shading or ray tracing, including light emitted from the sensor as well as stray light from other, non-correlated sources such as sunlight. Beams from the sensor and sensitivity of the receiving diodes are modeled with flexible beam steering patterns and with non-vanishing diameter.
  Different (all non-real time) computational approaches can be chosen based on system properties, computing capabilities, and desired output properties.
  Model parameters include system-specific properties, namely the physical spread of the LiDAR beam, combined with the sensitivity of the receiving diode; the intensity of the emitted light; the conversion between the intensity of reflected light and the echo pulse width; and scenario parameters such as environment lighting, positioning, and surface properties of the target(s) in the relevant infrared domain. System-specific properties of the model are determined from laboratory measurements of the photometric luminance on different target surfaces aligned with a goniometer at 0.01° resolution, which marks the best available resolution for measuring the beam pattern.
  The approach is calibrated for and tested on two automotive LiDAR systems, the Valeo Scala Gen. 2 and the Blickfeld Cube 1. Both systems differ notably in their properties and available interfaces, but the relevant model parameters could be extracted successfully.

---

